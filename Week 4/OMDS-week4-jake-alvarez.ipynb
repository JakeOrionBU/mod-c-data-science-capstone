{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31015ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Marketing Campaign] Columns:\n",
      "['ID', 'Year_Birth', 'Education', 'Marital_Status', 'Income', 'Kidhome', 'Teenhome', 'Dt_Customer', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Z_CostContact', 'Z_Revenue', 'Response']\n",
      "\n",
      "[Customer Churn] Columns:\n",
      "['CustomerID', 'Age', 'Gender', 'Tenure', 'Usage Frequency', 'Support Calls', 'Payment Delay', 'Subscription Type', 'Contract Length', 'Total Spend', 'Last Interaction', 'Churn']\n",
      "\n",
      "[Predict Conversion] Columns:\n",
      "['CustomerID', 'Age', 'Gender', 'Income', 'CampaignChannel', 'CampaignType', 'AdSpend', 'ClickThroughRate', 'ConversionRate', 'WebsiteVisits', 'PagesPerVisit', 'TimeOnSite', 'SocialShares', 'EmailOpens', 'EmailClicks', 'PreviousPurchases', 'LoyaltyPoints', 'AdvertisingPlatform', 'AdvertisingTool', 'Conversion']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load each dataset\n",
    "df_marketing = pd.read_csv(\"marketing_campaign_cleaned.csv\")\n",
    "df_churn = pd.read_csv(\"customer_churn_cleaned.csv\")\n",
    "df_conversion = pd.read_csv(\"predict_conversion_cleaned.csv\")\n",
    "\n",
    "print(\"\\n[Marketing Campaign] Columns:\")\n",
    "print(df_marketing.columns.tolist())\n",
    "\n",
    "print(\"\\n[Customer Churn] Columns:\")\n",
    "print(df_churn.columns.tolist())\n",
    "\n",
    "print(\"\\n[Predict Conversion] Columns:\")\n",
    "print(df_conversion.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac243e3",
   "metadata": {},
   "source": [
    "### Marketing Campaign Dataset Target = Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dede1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Marketing Campaign] Confusion Matrix:\n",
      "[[369   8]\n",
      " [ 45  22]]\n",
      "\n",
      "[Marketing Campaign] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93       377\n",
      "           1       0.73      0.33      0.45        67\n",
      "\n",
      "    accuracy                           0.88       444\n",
      "   macro avg       0.81      0.65      0.69       444\n",
      "weighted avg       0.87      0.88      0.86       444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Marketing Campaign Logistic Regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#load dataset\n",
    "df_marketing = pd.read_csv(\"marketing_campaign_cleaned.csv\")\n",
    "target = \"Response\"   # binary target column (0 = no response, 1 = responded)\n",
    "\n",
    "#drop ID and date fields that don't add predictive value\n",
    "df_marketing = df_marketing.drop(columns=[\"ID\", \"Dt_Customer\"], errors=\"ignore\")\n",
    "\n",
    "#split into features (X) and target (y)\n",
    "X = df_marketing.drop(columns=[target])\n",
    "y = df_marketing[target]\n",
    "\n",
    "#identify numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "#preprocessing: impute + scale numeric, impute + one-hot encode categorical\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, numeric_cols),\n",
    "    (\"cat\", categorical_pipe, categorical_cols)\n",
    "])\n",
    "\n",
    "#logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "\n",
    "#build full pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"model\", log_reg)\n",
    "])\n",
    "\n",
    "#train/test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#evaluate performance\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"\\n[Marketing Campaign] Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n[Marketing Campaign] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ae19e",
   "metadata": {},
   "source": [
    "### Observations: Marketing \n",
    "\n",
    "### Model Performance\n",
    "- **Accuracy**: 0.88 overall, driven mostly by strong performance on the majority class (non-responders).  \n",
    "- **Confusion Matrix**:\n",
    "  - True Negatives (no response predicted correctly): 369  \n",
    "  - False Positives (predicted response, but no response): 8  \n",
    "  - False Negatives (missed actual responses): 45  \n",
    "  - True Positives (response predicted correctly): 22  \n",
    "- **Precision/Recall**:\n",
    "  - Class `0` (non-response): Precision = 0.89, Recall = 0.98, F1 = 0.93  \n",
    "  - Class `1` (response): Precision = 0.73, Recall = 0.33, F1 = 0.45  \n",
    "\n",
    "### Interpretation\n",
    "- The model is **highly accurate at identifying non-responders**, but struggles to capture responders: recall for the positive class is only **0.33**, meaning two-thirds of actual responders are missed.  \n",
    "- This is consistent with the **class imbalance** in the dataset (responders are much fewer). Logistic regression leans toward the dominant class.  \n",
    "- The relatively high precision (0.73) for responders indicates that when the model does predict a response, it is usually correct â€” but it does so too rarely.  \n",
    "- For marketing use cases, this means the model could **conserve resources by avoiding wasted outreach** (low false positives), but at the cost of **missing many potential customers**.  \n",
    "\n",
    "*Note* ChatGpt used to help summarize Observations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa344fb",
   "metadata": {},
   "source": [
    "### Customer Churn Dataset Target = Churn  0 = No 1 = Yes \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b521cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Customer Churn] Confusion Matrix:\n",
      "[[34492  3675]\n",
      " [ 5731 44269]]\n",
      "\n",
      "[Customer Churn] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.90      0.88     38167\n",
      "         1.0       0.92      0.89      0.90     50000\n",
      "\n",
      "    accuracy                           0.89     88167\n",
      "   macro avg       0.89      0.89      0.89     88167\n",
      "weighted avg       0.89      0.89      0.89     88167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Customer Churn Logistic Regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#load dataset\n",
    "df_churn = pd.read_csv(\"customer_churn_cleaned.csv\")\n",
    "target = \"Churn\"   # binary target column (0 = retained, 1 = churned)\n",
    "\n",
    "#drop identifier column\n",
    "df_churn = df_churn.drop(columns=[\"CustomerID\"], errors=\"ignore\")\n",
    "\n",
    "#split into features and target\n",
    "X = df_churn.drop(columns=[target])\n",
    "y = df_churn[target]\n",
    "\n",
    "#identify numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "#preprocessing: impute + scale numeric, impute + one-hot encode categorical\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, numeric_cols),\n",
    "    (\"cat\", categorical_pipe, categorical_cols)\n",
    "])\n",
    "\n",
    "#logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "\n",
    "#build pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"model\", log_reg)\n",
    "])\n",
    "\n",
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#evaluate\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"\\n[Customer Churn] Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n[Customer Churn] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48904fce",
   "metadata": {},
   "source": [
    "### Observations: Customer Churn\n",
    "\n",
    "### Model Performance\n",
    "- **Accuracy**: 0.89 overall, showing strong predictive performance.  \n",
    "- **Confusion Matrix**:\n",
    "  - True Negatives (retained predicted correctly): 34,492  \n",
    "  - False Positives (predicted churn, but retained): 3,675  \n",
    "  - False Negatives (missed churners): 5,731  \n",
    "  - True Positives (churn predicted correctly): 44,269  \n",
    "- **Precision/Recall**:\n",
    "  - Class `0` (retained): Precision = 0.86, Recall = 0.90, F1 = 0.88  \n",
    "  - Class `1` (churn): Precision = 0.92, Recall = 0.89, F1 = 0.90  \n",
    "\n",
    "### Interpretation\n",
    "- The model performs well on both classes, with **balanced precision and recall**.  \n",
    "- It captures most churners (recall = 0.89) while also being precise when flagging them (precision = 0.92).  \n",
    "- The model misses ~5,700 churners, but correctly identifies ~44,000, making it highly useful for **retention strategies**.  \n",
    "- Performance is significantly stronger than in the **Marketing Campaign dataset**, confirming that churn is **more structured and predictable**.  \n",
    "\n",
    "*Note* ChatGPT used to help with observation summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9570333",
   "metadata": {},
   "source": [
    "### Predict Conversion Target = Conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6131875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Predict Conversion] Confusion Matrix:\n",
      "[[  34  164]\n",
      " [  10 1392]]\n",
      "\n",
      "[Predict Conversion] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.17      0.28       198\n",
      "           1       0.89      0.99      0.94      1402\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.83      0.58      0.61      1600\n",
      "weighted avg       0.88      0.89      0.86      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict Conversion Logistic Regression \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#load dataset\n",
    "df_conversion = pd.read_csv(\"predict_conversion_cleaned.csv\")\n",
    "target = \"Conversion\"   # binary target column (0 = no conversion, 1 = converted)\n",
    "\n",
    "#drop identifier column\n",
    "df_conversion = df_conversion.drop(columns=[\"CustomerID\"], errors=\"ignore\")\n",
    "\n",
    "#split into features and target\n",
    "X = df_conversion.drop(columns=[target])\n",
    "y = df_conversion[target]\n",
    "\n",
    "#identify numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "#preprocessing: impute + scale numeric, impute + one-hot encode categorical\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, numeric_cols),\n",
    "    (\"cat\", categorical_pipe, categorical_cols)\n",
    "])\n",
    "\n",
    "#logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "\n",
    "#build pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"model\", log_reg)\n",
    "])\n",
    "\n",
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#fit model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#evaluate\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"\\n[Predict Conversion] Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n[Predict Conversion] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b72189f",
   "metadata": {},
   "source": [
    "### Observations Predict Conversion \n",
    "\n",
    "### Model Performance\n",
    "- **Accuracy**: 0.89 overall, driven heavily by the dominant positive class (converted).  \n",
    "- **Confusion Matrix**:\n",
    "  - True Negatives (no conversion predicted correctly): 34  \n",
    "  - False Positives (predicted conversion, but no conversion): 164  \n",
    "  - False Negatives (missed conversions): 10  \n",
    "  - True Positives (conversion predicted correctly): 1,392  \n",
    "- **Precision/Recall**:\n",
    "  - Class `0` (no conversion): Precision = 0.77, Recall = 0.17, F1 = 0.28  \n",
    "  - Class `1` (conversion): Precision = 0.89, Recall = 0.99, F1 = 0.94  \n",
    "\n",
    "### Interpretation\n",
    "- The model is **extremely effective at detecting conversions** (recall = 0.99) while maintaining high precision (0.89).  \n",
    "- However, it performs poorly on the minority class (no conversions): recall = 0.17 means most non-converters are misclassified as converters.  \n",
    "- This imbalance skews the overall accuracy upward but **limits business utility**, since identifying non-converting customers is also valuable for targeted strategies.  \n",
    "- Compared to Marketing Campaign and Churn, this dataset demonstrates the strongest **bias toward the majority class**, highlighting the challenges of imbalanced data.  \n",
    "\n",
    "*Note* ChatGPT used to help with observation summary section\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
